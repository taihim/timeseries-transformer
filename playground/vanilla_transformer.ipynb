{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIamWxSojvV_",
    "outputId": "db9c1abd-e748-4931-9afa-80bf4dbe8282"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2024-05-16 04:34:10--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.2’\n",
      "\n",
      "\rinput.txt.2           0%[                    ]       0  --.-KB/s               \rinput.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-05-16 04:34:10 (35.4 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "id": "qGcEs3Zjjxsu"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vocab = sorted(list(set(text)))\n",
    "print(f\"Vocab size: {len(vocab)}\", \"\".join(vocab))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Td75Q2QTjymC",
    "outputId": "111a4f1e-b733-4647-c182-14692c53a7d4"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocab size: 65 \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# map chars to int and vice versa\n",
    "chtoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "itoch = {i: ch for i, ch in enumerate(vocab)}"
   ],
   "metadata": {
    "id": "QyUrpeF0j_wT"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# functions to encode/decode text\n",
    "encode = lambda input_str: [chtoi[ch] for ch in input_str]\n",
    "decode = lambda input_arr: \"\".join([itoch[i] for i in input_arr])"
   ],
   "metadata": {
    "id": "NAxMPgazlY8J"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# encode the data\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ],
   "metadata": {
    "id": "uPEFo4S-lV86"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 1115395 tokens\n",
    "data.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "za9Fm4FHmMLF",
    "outputId": "16a7a8ff-0313-4465-8360-d608ab7b3dd4"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Split up the data into train and validation sets. First 90% will be train, rest val\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ],
   "metadata": {
    "id": "SfnZlkY5mZCn"
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# we create chunks from the dataset since we cannot feed all data at once\n",
    "# max length of these chunks is called block_size/context_length\n",
    "# we are going to set it to 8 for now\n",
    "ctx_len = 8"
   ],
   "metadata": {
    "id": "YJQI5wddm2wx"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# there are multiple examples in one chunk\n",
    "# this loop demonstrates this\n",
    "\n",
    "x = train_data[:ctx_len]\n",
    "y = train_data[1:ctx_len+1]\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "for i in range(ctx_len):\n",
    "  context = x[:i+1]\n",
    "  target = y[i]\n",
    "\n",
    "  print(f\"For context: {context}, target is: {target}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8efMnz7onjL1",
    "outputId": "57be3e60-caf1-4cc0-e7be-580cff8042ea"
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "For context: tensor([18]), target is: 47\n",
      "For context: tensor([18, 47]), target is: 56\n",
      "For context: tensor([18, 47, 56]), target is: 57\n",
      "For context: tensor([18, 47, 56, 57]), target is: 58\n",
      "For context: tensor([18, 47, 56, 57, 58]), target is: 1\n",
      "For context: tensor([18, 47, 56, 57, 58,  1]), target is: 15\n",
      "For context: tensor([18, 47, 56, 57, 58,  1, 15]), target is: 47\n",
      "For context: tensor([18, 47, 56, 57, 58,  1, 15, 47]), target is: 58\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "n_embd = 32"
   ],
   "metadata": {
    "id": "oftAYxhvR4pm"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# create batches of sequences for training\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # 4 independant sequences will be processed by the transformer in parallel\n",
    "vocab_size = 65\n",
    "def get_batch(split):\n",
    "  data = train_data if split == \"train\" else val_data\n",
    "  ix = torch.randint(len(data)-ctx_len, (batch_size,)) # list of 4 random integers that are used as indexes to get data\n",
    "  x = torch.stack([data[i:i+ctx_len] for i in ix])\n",
    "  y = torch.stack([data[i+1:i+ctx_len+1] for i in ix])\n",
    "  return x, y\n",
    "\n",
    "x, y = get_batch('train')"
   ],
   "metadata": {
    "id": "ZbZPy9HfoB5-"
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(x)\n",
    "print(y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMITh4hTrvTb",
    "outputId": "411ad66f-3b1e-4ea0-9d75-f9742b2b302e"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8_GErzonZS-",
    "outputId": "03a1ff12-b516-4083-adcd-ec483dac6b6d"
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdNGYs80TOHT",
    "outputId": "8c5e028f-82a1-4050-e737-d361052d012c"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5UbVKw0pRZY",
    "outputId": "1466669e-cbf1-4129-f139-71166800661f"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7def07f4ae90>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dropout=0.2"
   ],
   "metadata": {
    "id": "qu91FnZLnzUC"
   },
   "execution_count": 144,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Head(nn.Module):\n",
    "  def __init__(self, head_size):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.register_buffer('tril', torch.tril(torch.ones(ctx_len, ctx_len)))\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "    B,T,C = x.shape\n",
    "    k = self.key(x)\n",
    "    q = self.query(x)\n",
    "\n",
    "    wei = q @ k.transpose(-2, -1) * C ** -0.5\n",
    "    wei = wei.masked_fill(self.tril[:T, :T]==0, float(\"-inf\"))\n",
    "    wei = F.softmax(wei, dim=-1)\n",
    "    wei = self.dropout(wei)\n",
    "\n",
    "    v=self.value(x)\n",
    "    out = wei @ v\n",
    "\n",
    "    return out\n"
   ],
   "metadata": {
    "id": "04_EFEdeeJs5"
   },
   "execution_count": 138,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, num_heads, head_size):\n",
    "    super().__init__()\n",
    "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "    self.proj = nn.Linear(n_embd, n_embd)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "    out = self.dropout(self.proj(out))\n",
    "    return out\n"
   ],
   "metadata": {
    "id": "MxoEVJGlhTtT"
   },
   "execution_count": 139,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, n_embd):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(n_embd, 4 * n_embd),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4 * n_embd, n_embd), # projection layer\n",
    "        nn.Dropout(dropout),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.net(x)\n"
   ],
   "metadata": {
    "id": "X1LH3xPjitZ0"
   },
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self, n_embd, n_head):\n",
    "    super().__init__()\n",
    "    head_size = n_embd // n_head\n",
    "    self.sa = MultiHeadAttention(n_head, head_size)\n",
    "    self.ffwd = FeedForward(n_embd)\n",
    "    self.ln1 = nn.LayerNorm(n_embd)\n",
    "    self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.sa(self.ln1(x))\n",
    "    x = x + self.ffwd(self.ln2(x))\n",
    "\n",
    "    return x"
   ],
   "metadata": {
    "id": "-hdLuOlkkHj4"
   },
   "execution_count": 141,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TransformerModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "    self.position_embedding_table = nn.Embedding(ctx_len, n_embd)\n",
    "    # self.sa_head = Head(n_embd)\n",
    "    # self.sa_heads = MultiHeadAttention(4, n_embd//4)\n",
    "    # self.ffwd = FeedForward(n_embd)\n",
    "    self.blocks = nn.Sequential(\n",
    "        Block(n_embd, n_head=4),\n",
    "        Block(n_embd, n_head=4),\n",
    "        Block(n_embd, n_head=4),\n",
    "        nn.LayerNorm(n_embd),\n",
    "    )\n",
    "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "\n",
    "  def forward(self, x, y=None):\n",
    "    B,T = x.shape\n",
    "\n",
    "    tok_emb = self.token_embedding_table(x) # B,T,n_embd tensor\n",
    "    pos_emb = self.position_embedding_table(torch.arange(T)) # T, n_embd\n",
    "    emb = tok_emb + pos_emb # B,T, n_embd\n",
    "    # emb = self.sa_head(emb)\n",
    "    # emb = self.sa_heads(emb)\n",
    "    # emb = self.ffwd(emb)\n",
    "    emb = self.blocks(emb)\n",
    "    logits = self.lm_head(emb) # B,T,vocab_size (4,8,32 in this case)\n",
    "\n",
    "    if y is None:\n",
    "      loss = None\n",
    "    else:\n",
    "      B, T, C = logits.shape\n",
    "      logits = logits.view(B*T, C)\n",
    "      y = y.view(B*T)\n",
    "      loss = F.cross_entropy(logits, y) # logits is B,T,C, y is B,T,1\n",
    "    return logits, loss\n",
    "\n",
    "  def generate(self, idx, max_new_tokens):\n",
    "    # idx is a B,T array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "      idx_cond = idx[:, -ctx_len:]\n",
    "      logits, _ = self(idx_cond)\n",
    "      # get only last time step\n",
    "      logits = logits[:, -1, :] # (B, C)\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      idx_next = torch.multinomial(probs, num_samples=1)\n",
    "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "    return idx\n"
   ],
   "metadata": {
    "id": "27qfgvCxpRbm"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "m = TransformerModel()\n",
    "logits, loss = m(x, y)"
   ],
   "metadata": {
    "id": "12p9QTKjpRf0"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "logits.shape"
   ],
   "metadata": {
    "id": "21FRKH4st2Cv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsggpbQOt8L8",
    "outputId": "66c07fa1-66f6-4ab2-a85b-840be1da4f35"
   },
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(4.2769, grad_fn=<NllLossBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "logits[-1, :]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6NPik8bu_jK",
    "outputId": "1de2c577-a44a-4a4f-9706-9f46e7d56dd7"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-9.7801e-02,  3.0377e-01,  5.3225e-01,  3.1163e-01,  4.9935e-01,\n",
       "        -1.6922e-01, -6.6894e-01,  2.5641e-01,  1.2328e-01, -8.2984e-01,\n",
       "         1.3829e+00, -2.7566e-01, -7.6557e-01, -7.0552e-01,  1.3452e-01,\n",
       "         6.6854e-01,  1.3065e-01,  1.4249e+00,  9.0741e-01,  7.0440e-01,\n",
       "         1.6653e-01,  1.0804e+00, -3.6346e-01,  3.2648e-04, -5.7357e-01,\n",
       "        -1.7159e-01,  4.3415e-01, -5.5920e-01,  5.8686e-01, -5.5445e-01,\n",
       "        -3.8486e-01,  5.8431e-01, -1.0340e+00, -2.3409e-01, -7.0003e-02,\n",
       "         4.3208e-01, -6.0286e-01, -2.1157e-01, -1.2753e-01,  2.1167e-01,\n",
       "        -1.4425e-01,  4.8266e-01, -2.7369e-02,  4.9492e-02, -4.4185e-01,\n",
       "        -2.2223e-01, -1.0623e+00, -3.6501e-01, -9.6334e-01, -4.5618e-01,\n",
       "        -3.0483e-02, -3.0194e-01, -2.2461e-01,  4.7548e-01,  8.9477e-01,\n",
       "        -1.0481e+00,  7.2695e-04,  5.0593e-01, -8.4274e-01, -3.1749e-01,\n",
       "        -7.3505e-01,  2.3815e-01,  3.3408e-01,  6.0319e-02, -1.2787e-01],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "idx1 = torch.zeros((1,1), dtype=torch.long)\n",
    "output1 = m.generate(idx1, max_new_tokens=100)\n",
    "print(decode(output1[0].tolist()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xO9AI6LzSr6",
    "outputId": "3d598673-81b5-4dad-ba75-a13d9c9028cb"
   },
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Mgh&pPVMPEUfLBvpg$Gg!;FJUH!u!UxHJBFNkTgJG?ZWq''pfuPyPBlnqp$esqgj:kCNtHZ eZyuuUtE FNWCa:O'&BIIurFdogg\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "eval_iters = 200\n",
    "\n",
    "# context manager tells pytorch that w/e happens in the function, we wont call backward() on it\n",
    "# so it doesnt need to store the intermediate values for backprop, is more memory efficient this way\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "  out = {}\n",
    "  # set model to eval mode\n",
    "  m.eval()\n",
    "  for split in ['train', 'val']:\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "      X, Y = get_batch(split)\n",
    "      logits, loss = m(X, Y)\n",
    "      losses[k] = loss.item()\n",
    "    out[split] = losses.mean()\n",
    "  # set it back to training mode\n",
    "  m.train()\n",
    "  return out"
   ],
   "metadata": {
    "id": "3KAEZoDQ7-pI"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "eval_interval = 300\n",
    "batch_size = 32\n",
    "for iter in range(5000):\n",
    "  xb, yb = get_batch('train')\n",
    "\n",
    "  if iter % eval_interval == 0:\n",
    "    losses=estimate_loss()\n",
    "    print(f\"step {iter}: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
    "\n",
    "  logits, loss = m(xb, yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tsx994_ZUllI",
    "outputId": "a226115b-f92e-49ad-9844-a111328b878d"
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 0: train loss: 4.3412, val loss: 4.3334\n",
      "step 300: train loss: 2.5476, val loss: 2.5511\n",
      "step 600: train loss: 2.4192, val loss: 2.4428\n",
      "step 900: train loss: 2.3592, val loss: 2.3643\n",
      "step 1200: train loss: 2.2943, val loss: 2.3191\n",
      "step 1500: train loss: 2.2700, val loss: 2.2759\n",
      "step 1800: train loss: 2.2323, val loss: 2.2484\n",
      "step 2100: train loss: 2.2009, val loss: 2.2340\n",
      "step 2400: train loss: 2.2004, val loss: 2.2178\n",
      "step 2700: train loss: 2.1743, val loss: 2.1946\n",
      "step 3000: train loss: 2.1599, val loss: 2.1772\n",
      "step 3300: train loss: 2.1579, val loss: 2.1635\n",
      "step 3600: train loss: 2.1219, val loss: 2.1647\n",
      "step 3900: train loss: 2.1266, val loss: 2.1690\n",
      "step 4200: train loss: 2.1054, val loss: 2.1467\n",
      "step 4500: train loss: 2.1105, val loss: 2.1391\n",
      "step 4800: train loss: 2.1118, val loss: 2.1445\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n686H8w86LaE",
    "outputId": "dd8ff1d4-645a-4a38-a52a-e4de68a5b9da"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 0: train loss: 4.3239, val loss: 4.3302\n",
      "step 300: train loss: 0.7795, val loss: 0.8203\n",
      "step 600: train loss: 0.4255, val loss: 0.4284\n",
      "step 900: train loss: 0.3537, val loss: 0.3594\n",
      "step 1200: train loss: 0.3383, val loss: 0.3412\n",
      "step 1500: train loss: 0.3232, val loss: 0.3228\n",
      "step 1800: train loss: 0.3167, val loss: 0.3170\n",
      "step 2100: train loss: 0.3116, val loss: 0.3131\n",
      "step 2400: train loss: 0.3064, val loss: 0.3080\n",
      "step 2700: train loss: 0.3088, val loss: 0.3046\n",
      "step 3000: train loss: 0.2941, val loss: 0.2984\n",
      "step 3300: train loss: 0.3036, val loss: 0.2974\n",
      "step 3600: train loss: 0.2936, val loss: 0.2955\n",
      "step 3900: train loss: 0.2906, val loss: 0.2924\n",
      "step 4200: train loss: 0.2931, val loss: 0.2964\n",
      "step 4500: train loss: 0.2850, val loss: 0.2896\n",
      "step 4800: train loss: 0.2882, val loss: 0.2882\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "idx1 = torch.zeros((1,1), dtype=torch.long)\n",
    "output1 = m.generate(idx1, max_new_tokens=250)\n",
    "print(decode(output1[0].tolist()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KFrp9ow6ql1",
    "outputId": "a72f2d2c-882a-40eb-be35-6abe4f4763df"
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "ENRIYILIET:\n",
      "Toe whil lyeft horguwn to sorrint. I dertle\n",
      "Sel:\n",
      "When, with my chot\n",
      "Hachasim liod sont be of lay striue, which his bleaiep, num:\n",
      "The plas ard oks lold st\n",
      "And tame'dain with his of sany-ron' wath I me\n",
      "Dold Sorcanght hand shous if I cecher.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# self attention\n",
    "# before going to proper attention, lets do a naive implementation\n",
    "# just take the average of all token embeddings before the current token and store it as the new embedding for current token\n",
    "\n",
    "B,T,C = 1,8,2\n",
    "x1 = torch.randn(B,T,C)\n",
    "x1.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ts-KuCZX7MOJ",
    "outputId": "49dab2ae-63b6-4357-9523-097479fbd4b7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 279
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x1[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1OMjGbA_ehx",
    "outputId": "70cf55d0-e52c-4997-c380-5034cd7835b1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.6050, -0.1067],\n",
       "        [-0.4457,  0.8633],\n",
       "        [ 0.1946, -0.2494],\n",
       "        [-1.4561, -0.4149],\n",
       "        [ 1.2283,  0.4399],\n",
       "        [ 0.6590, -0.8875],\n",
       "        [-0.1064, -1.4840],\n",
       "        [-0.5361,  0.7781]])"
      ]
     },
     "metadata": {},
     "execution_count": 284
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# this does what we want but it is a nested loop and inefficient\n",
    "xbow = torch.zeros(B,T,C)\n",
    "for b in range(B):\n",
    "  for t in range(T):\n",
    "    xbow[b, t] = torch.mean(x1[b, :t+1], 0)"
   ],
   "metadata": {
    "id": "_dMkA_Zo_nMb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "xbow[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcfdNjo7AbKi",
    "outputId": "2ebd3fe3-75b1-4147-b0f2-10769344c5a2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.6050, -0.1067],\n",
       "        [-0.5254,  0.3783],\n",
       "        [-0.2854,  0.1691],\n",
       "        [-0.5781,  0.0231],\n",
       "        [-0.2168,  0.1065],\n",
       "        [-0.0708, -0.0592],\n",
       "        [-0.0759, -0.2627],\n",
       "        [-0.1334, -0.1326]])"
      ]
     },
     "metadata": {},
     "execution_count": 291
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# we can make use of matrix multiplications to parallelize the job\n",
    "avg_mat = torch.tril(torch.ones(T,T))\n",
    "avg_mat = avg_mat / torch.sum(avg_mat, 1, keepdim=True)"
   ],
   "metadata": {
    "id": "zaJALxP5DHln"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "xbow2 = avg_mat @ x1"
   ],
   "metadata": {
    "id": "9pLtXRR3HH__"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "xbow2[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D543o1V-Ho9W",
    "outputId": "293d41f4-3f34-47c1-e222-ac6c57811cc1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.6050, -0.1067],\n",
       "        [-0.5254,  0.3783],\n",
       "        [-0.2854,  0.1691],\n",
       "        [-0.5781,  0.0231],\n",
       "        [-0.2168,  0.1065],\n",
       "        [-0.0708, -0.0592],\n",
       "        [-0.0759, -0.2627],\n",
       "        [-0.1334, -0.1326]])"
      ]
     },
     "metadata": {},
     "execution_count": 346
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x1.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZnFfXf8IBWv",
    "outputId": "d12395e2-2100-440b-b7e8-2ad7a67f79cc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 349
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "avg_mat.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUzZAQSxICM2",
    "outputId": "18dde482-ae20-4d4e-b911-43663afff298"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 350
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.allclose(xbow, xbow2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wncq95adIZ8j",
    "outputId": "cf21cf58-5e13-48a0-818e-8653539bff9e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 351
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# we can get the same avg_mat using softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "tril"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1SCSOSWIfJ_",
    "outputId": "a945dec2-9b5e-410a-d457-977155d7f28e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 353
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# weights\n",
    "wei = torch.zeros(T,T)\n",
    "wei"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xX64m5osJDA5",
    "outputId": "898310a1-9a04-4dbc-c3a0-1dff1fdacc10"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 364
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGcZN8pOJJXu",
    "outputId": "e510b562-2d11-47d5-ef80-99f4d4f949cc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 365
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "wei = F.softmax(wei, dim=1)"
   ],
   "metadata": {
    "id": "eXwnr8qVJO87"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wei"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWAk8p8qJcT7",
    "outputId": "af64ae92-b7cf-429c-9438-d252db63abaf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "metadata": {},
     "execution_count": 367
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "xbow3 = wei @ x1"
   ],
   "metadata": {
    "id": "RmNHQOXJJtHV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.allclose(xbow3, xbow2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrk-fBuaJcjl",
    "outputId": "31c304d3-4ed4-47e8-bf6a-31a29e790642"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 372
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1337)\n",
    "# self attention\n",
    "B, T, C = 4, 8, 32\n",
    "x2 = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x2) # B, T, 16\n",
    "q = query(x2) # B, T, 16\n",
    "\n",
    "# scaled dot product attention. i.e divide by sqrt of head_size\n",
    "wei = q @ k.transpose(-2, -1) * head_size**0.5 # B,T,T\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "# wei = wei.masked_fill(tril==0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "\n",
    "v = value(x2)\n",
    "\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "O0GcJg9HJmCe",
    "outputId": "1431f316-b6b2-4832-e619-5d1905ea5a57"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-95003b153d49>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmanual_seed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1337\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m# self attention\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mB\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mC\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m8\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m32\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mx2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mB\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mC\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "wei.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i27VNw_5XQ3q",
    "outputId": "b4846f9b-d33d-415c-882c-9dbe38dc1ccd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 493
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x2.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWc0gWwaXQ5v",
    "outputId": "15c1f96e-b8d9-40c7-f506-459ad6897fa1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 494
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "wei.var()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4MFq_Sfas5U",
    "outputId": "28b8d82f-9970-458d-e66b-25f7e7083e78"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0921, grad_fn=<VarBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 495
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "id": "XBEhwy5XdfOk"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0"
   ],
   "metadata": {
    "id": "89O0IqePdfQ1"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.int64)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)"
   ],
   "metadata": {
    "id": "4wKlmWQllcRS"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Head(nn.Module):\n",
    "  def __init__(self, head_size):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.register_buffer('tril', torch.tril(torch.ones(ctx_len, ctx_len)))\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x):\n",
    "    B,T,C = x.shape\n",
    "    k = self.key(x)\n",
    "    q = self.query(x)\n",
    "\n",
    "    wei = q @ k.transpose(-2, -1) * C ** -0.5\n",
    "    # wei = wei.masked_fill(self.tril[:T, :T]==0, float(\"-inf\"))\n",
    "    wei = F.softmax(wei, dim=-1)\n",
    "    wei = self.dropout(wei)\n",
    "\n",
    "    v=self.value(x)\n",
    "    out = wei @ v\n",
    "\n",
    "    return out"
   ],
   "metadata": {
    "id": "bIC354xo5D5s"
   },
   "execution_count": 166,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TimeSeriesTransformerModel(nn.Module):\n",
    "    def __init__(self, n_embd, ctx_len, dropout, num_classes):\n",
    "        super().__init__()\n",
    "        self.input_projection = nn.Linear(1, n_embd)  # Project single feature to embedding dimension\n",
    "        self.position_embedding_table = nn.Embedding(ctx_len, n_embd)\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            nn.LayerNorm(n_embd),\n",
    "        )\n",
    "        self.classification_head = nn.Linear(n_embd, num_classes)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        B, T, D = x.shape  # B is batch size, T is sequence length\n",
    "\n",
    "        tok_emb = self.input_projection(x)  # B, T, n_embd tensor\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=x.device))  # T, n_embd\n",
    "        emb = tok_emb + pos_emb  # B, T, n_embd\n",
    "        emb = self.blocks(emb)\n",
    "        emb = emb.mean(dim=1)  # Pooling: mean of the sequence (B, n_embd)\n",
    "        logits = self.classification_head(emb)  # B, num_classes\n",
    "\n",
    "        if y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, y)  # logits is B, num_classes and y is B\n",
    "\n",
    "        return logits, loss\n",
    "\n"
   ],
   "metadata": {
    "id": "o7zF9yxClisO"
   },
   "execution_count": 217,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "n_embd = 128  # Embedding dimension\n",
    "ctx_len = 500  # Context length, the length of the time series data\n",
    "dropout = 0.1  # Dropout rate\n",
    "num_classes = 2  # Number of classes for classification\n",
    "\n",
    "# Initialize model\n",
    "ts_model = TimeSeriesTransformerModel(n_embd, ctx_len, dropout, num_classes)\n"
   ],
   "metadata": {
    "id": "ONASJe2sBgTK"
   },
   "execution_count": 218,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "I6gWIDMmBgWM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_dim = 1  # Number of input features per time step\n",
    "n_embd = 128  # Embedding dimension\n",
    "ctx_len = 500  # Length of the input sequence\n",
    "n_head = 4 #8  # Number of attention heads\n",
    "n_layer = 2 #3  # Number of transformer blocks\n",
    "\n",
    "ts_model = TimeSeriesTransformerModel(input_dim, n_embd, ctx_len, n_head, n_layer)\n",
    "\n",
    "# logits, loss = ts_model(torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))"
   ],
   "metadata": {
    "id": "HLFZNoKEp2HT"
   },
   "execution_count": 206,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eval_iters = 200\n",
    "# context manager tells pytorch that w/e happens in the function, we wont call backward() on it\n",
    "# so it doesnt need to store the intermediate values for backprop, is more memory efficient this way\n",
    "@torch.no_grad()\n",
    "def estimate_loss2():\n",
    "  out = {}\n",
    "  # set model to eval mode\n",
    "  ts_model.eval()\n",
    "  for split in ['train', 'val']:\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "      X, Y = get_batch2(split)\n",
    "      logits, loss = ts_model(X, Y)\n",
    "      losses[k] = loss.item()\n",
    "    out[split] = losses.mean()\n",
    "  # set it back to training mode\n",
    "  ts_model.train()\n",
    "  return out"
   ],
   "metadata": {
    "id": "Oh1W4jFXrpA2"
   },
   "execution_count": 219,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eval_interval = 100\n",
    "batch_size = 1"
   ],
   "metadata": {
    "id": "mbpwGAd0s0TA"
   },
   "execution_count": 232,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.AdamW(ts_model.parameters(), lr=1e-3)\n",
    "\n",
    "for iter in range(1000):\n",
    "  xb, yb = get_batch2('train')\n",
    "\n",
    "  # if iter % eval_interval == 0:\n",
    "  #   losses=estimate_loss2()\n",
    "  #   print(f\"step {iter}: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
    "\n",
    "  logits, loss = ts_model(xb, yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  # if iter % eval_interval == 0:\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  ts_model.eval()\n",
    "  with torch.no_grad():\n",
    "      logits, _ = ts_model(xb)\n",
    "      predictions = torch.argmax(logits, dim=1)\n",
    "      accuracy = (predictions == yb).float().mean().item()\n",
    "      print(f'Accuracy: {accuracy * 100:.2f}%')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "T4kY56_WqEfO",
    "outputId": "ad044374-2b04-4f78-ebf4-b5475d4f2891"
   },
   "execution_count": 226,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-22-4ad59145bc21>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(torch.stack([labels[i] for i in ix]), dtype=torch.int64)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 68.75%\n",
      "Accuracy: 68.75%\n",
      "Accuracy: 59.38%\n",
      "Accuracy: 53.12%\n",
      "Accuracy: 65.62%\n",
      "Accuracy: 65.62%\n",
      "Accuracy: 37.50%\n",
      "Accuracy: 34.38%\n",
      "Accuracy: 59.38%\n",
      "Accuracy: 50.00%\n",
      "Accuracy: 40.62%\n",
      "Accuracy: 65.62%\n",
      "Accuracy: 40.62%\n",
      "Accuracy: 40.62%\n",
      "Accuracy: 46.88%\n",
      "Accuracy: 40.62%\n",
      "Accuracy: 59.38%\n",
      "Accuracy: 59.38%\n",
      "Accuracy: 53.12%\n",
      "Accuracy: 62.50%\n",
      "Accuracy: 68.75%\n",
      "Accuracy: 46.88%\n",
      "Accuracy: 50.00%\n",
      "Accuracy: 59.38%\n",
      "Accuracy: 40.62%\n",
      "Accuracy: 46.88%\n",
      "Accuracy: 50.00%\n",
      "Accuracy: 50.00%\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-226-695129b94a56>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m   \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset_to_none\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m   \u001B[0;31m# if iter % eval_interval == 0:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m   \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m   \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    520\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    521\u001B[0m             )\n\u001B[0;32m--> 522\u001B[0;31m         torch.autograd.backward(\n\u001B[0m\u001B[1;32m    523\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    524\u001B[0m         )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    264\u001B[0m     \u001B[0;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m     \u001B[0;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    267\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m         \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "xb, yb = get_batch2('train')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ud_Un_KFHjIG",
    "outputId": "4f2ea39f-7d53-4533-d7c7-ec70647553e9"
   },
   "execution_count": 233,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-22-4ad59145bc21>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(torch.stack([labels[i] for i in ix]), dtype=torch.int64)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "xb.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujZBanOUHwFR",
    "outputId": "1906860a-50cf-4cd2-91e5-2951b1989411"
   },
   "execution_count": 235,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 235
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "res, loss = ts_model(xb)"
   ],
   "metadata": {
    "id": "cMKMft0OHkob"
   },
   "execution_count": 240,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "res"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5wPt87cH58T",
    "outputId": "48273efb-cd62-46aa-91b7-b286728cb505"
   },
   "execution_count": 246,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0811, -0.1454]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "yb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUb79KGEH7CU",
    "outputId": "1e53d9a7-4620-43fe-85b2-7e7f3b356339"
   },
   "execution_count": 248,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "metadata": {},
     "execution_count": 248
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "F.cross_entropy(res, yb)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQZ8Hj9BHkqh",
    "outputId": "62fed344-6758-435a-9597-57a46c8c36bf"
   },
   "execution_count": 244,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.5863, grad_fn=<NllLossBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 244
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "|for epoch in range(epochs):\n",
    "    ts_model.train()\n",
    "    logits, loss = ts_model(x, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    # Evaluate the model (optional)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(x)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        accuracy = (predictions == y).float().mean().item()\n",
    "        print(f'Accuracy: {accuracy * 100:.2f}%')"
   ],
   "metadata": {
    "id": "gkkp0VSWC20A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "logits"
   ],
   "metadata": {
    "id": "-GTsm-v7qYZF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.catx_test[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dgfpmt6o3_ZW",
    "outputId": "5ed35b1e-e4aa-49be-9254-295be7991afb"
   },
   "execution_count": 154,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([500, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "res1 = ts_model(x_test[5].unsqueeze(0).to(torch.float32))\n",
    "res1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXhY11Ap3z7D",
    "outputId": "0a551319-ed80-400c-ff1b-4521c996a20f"
   },
   "execution_count": 177,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.0451, -0.1226]], grad_fn=<AddmmBackward0>), None)"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_test[5]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5hILPwg4cqJ",
    "outputId": "105be994-5b4a-4bcd-c159-955641b689a2"
   },
   "execution_count": 178,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "loss"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "toqooGSEyqci",
    "outputId": "3b4654be-9ee3-48cb-bdbf-ea8cb9897326"
   },
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.1010, grad_fn=<NllLossBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_batch2(split):\n",
    "  data = x_train if split == \"train\" else x_test\n",
    "  labels = y_train if split == \"train\" else y_test\n",
    "  ix = torch.randint(len(data)-ctx_len, (batch_size,)) # list of 4 random integers that are used as indexes to get data\n",
    "  x = torch.stack([data[i] for i in ix])\n",
    "  y = torch.tensor(torch.stack([labels[i] for i in ix]), dtype=torch.int64)\n",
    "  return x, y"
   ],
   "metadata": {
    "id": "CyF6dwFzqcDh"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ee, fee = get_batch2('train')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VF3Hr9ADs7KQ",
    "outputId": "6acb5b2f-0bf2-4569-a5c1-e26f94564f48"
   },
   "execution_count": 117,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([32])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-116-da46520fd1f0>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(torch.stack([labels[i] for i in ix]), dtype=torch.int64)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "p9TZuEKLs2Rs"
   },
   "execution_count": 117,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ee.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzZ-sen-sQaw",
    "outputId": "f1ecd930-c4fe-4952-90c0-244f0d3054d4"
   },
   "execution_count": 118,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32, 500, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fee.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8-wvmapsWao",
    "outputId": "e7f180e2-a7a3-4482-9bb7-b547f368496c"
   },
   "execution_count": 119,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fee.dtype"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wghQ5I1tvyP",
    "outputId": "8836f66b-1b0e-4829-8a5e-3030d21b167a"
   },
   "execution_count": 120,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ee.dtype"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJ0ZWODjtxV_",
    "outputId": "dec0f8bb-62d4-440d-d4cb-9cacf5f8c5fa"
   },
   "execution_count": 121,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_test.dtype"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aanh5FLXut02",
    "outputId": "15d65c16-6c0d-4dcb-d5ca-fdc3dfc077cb"
   },
   "execution_count": 122,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fee"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-9NnpNduwdl",
    "outputId": "594e13ef-31fb-4081-bdf2-89a7a50a23cd"
   },
   "execution_count": 105,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "opyxFJPAu3EW"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
